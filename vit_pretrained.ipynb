{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreas\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import lightning as L\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import vit_b_16 # pretrained model\n",
    "from torchsummary import summary\n",
    "import torchmetrics\n",
    "\n",
    "import brain_tumor_dataset as btd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\ttransforms.Grayscale(num_output_channels=3),\t# convert to 3 channels\n",
    "\ttransforms.Resize((224, 224)), \t\t\t\t\t# resize to 224x224\n",
    "\ttransforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = btd.BrainTumorDataset(btd.TRAIN_DATA_PATH, transform=transform)\n",
    "test_dataset = btd.BrainTumorDataset(btd.TEST_DATA_PATH, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n",
      "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)\n",
    "print(test_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Conv2d: 1-1                                 [-1, 768, 14, 14]         590,592\n",
      "├─Encoder: 1-2                                [-1, 197, 768]            --\n",
      "|    └─Dropout: 2-1                           [-1, 197, 768]            --\n",
      "|    └─Sequential: 2-2                        [-1, 197, 768]            --\n",
      "|    |    └─EncoderBlock: 3-1                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-2                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-3                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-4                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-5                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-6                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-7                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-8                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-9                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-10                [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-11                [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-12                [-1, 197, 768]            7,087,872\n",
      "|    └─LayerNorm: 2-3                         [-1, 197, 768]            1,536\n",
      "├─Linear: 1-3                                 [-1, 4]                   3,076\n",
      "===============================================================================================\n",
      "Total params: 85,649,668\n",
      "Trainable params: 85,649,668\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 455.42\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 30.01\n",
      "Params size (MB): 326.73\n",
      "Estimated Total Size (MB): 357.31\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Conv2d: 1-1                                 [-1, 768, 14, 14]         590,592\n",
       "├─Encoder: 1-2                                [-1, 197, 768]            --\n",
       "|    └─Dropout: 2-1                           [-1, 197, 768]            --\n",
       "|    └─Sequential: 2-2                        [-1, 197, 768]            --\n",
       "|    |    └─EncoderBlock: 3-1                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-2                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-3                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-4                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-5                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-6                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-7                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-8                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-9                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-10                [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-11                [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-12                [-1, 197, 768]            7,087,872\n",
       "|    └─LayerNorm: 2-3                         [-1, 197, 768]            1,536\n",
       "├─Linear: 1-3                                 [-1, 4]                   3,076\n",
       "===============================================================================================\n",
       "Total params: 85,649,668\n",
       "Trainable params: 85,649,668\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 455.42\n",
       "===============================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 30.01\n",
       "Params size (MB): 326.73\n",
       "Estimated Total Size (MB): 357.31\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load pre-trained model\n",
    "model = vit_b_16(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Modify for 4 classes\n",
    "model.heads = torch.nn.Linear(model.hidden_dim, 4) \n",
    "\n",
    "model = model.to(device)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for current batch\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Calculate and print average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(module, input, output):\n",
    "    print(module)\n",
    "    print(f\"Input shape: {input[0].shape}\")\n",
    "    print(f\"Output shape: {output[0].shape}\")\n",
    "    print(\"===\")\n",
    "\n",
    "# Register the hook to the multihead attention module\n",
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.MultiheadAttention):\n",
    "        module.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model_pretrained.pth\", weights_only=True, map_location=device))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\n",
    "\tfor inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "\t\tinputs, labels = inputs.to(device), labels.to(device)\n",
    "\t\toutputs = model(inputs)\n",
    "\t\tpredictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "\t\ttotal += labels.size(0)\n",
    "\t\tcorrect += (predictions == labels).sum().item()\n",
    "\n",
    "\taccuracy = correct / total\n",
    "\tprint(f'Accuracy on the test set: {accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Andreas\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "# Define the transformation for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),   # convert to 3 channels\n",
    "    transforms.Resize((224, 224)),                 # resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load your datasets with the defined transformations\n",
    "train_dataset = btd.BrainTumorDataset(btd.TRAIN_DATA_PATH, transform=transform)\n",
    "test_dataset = btd.BrainTumorDataset(btd.TEST_DATA_PATH, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(module)\n",
    "    print(f\"Input shape: {input[0].shape}\")\n",
    "    print(f\"Output shape: {output[0].shape}\")\n",
    "    print(\"===\")\n",
    "\n",
    "# Define the PyTorch Lightning Module\n",
    "class BrainTumorClassifier(L.LightningModule):\n",
    "\tdef __init__(self, learning_rate=1e-4):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# Initialize the model with the pre-trained ViT\n",
    "\t\tself.model = vit_b_16(weights='IMAGENET1K_V1')\n",
    "\t\tself.model.heads = torch.nn.Linear(self.model.hidden_dim, 4)  # Modify for 4 classes\n",
    "\n",
    "\t\t# Define loss function and learning rate\n",
    "\t\tself.criterion = torch.nn.CrossEntropyLoss()\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\n",
    "\t\t# Initialize accuracy metric for logging\n",
    "\t\tself.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=4)\n",
    "\t\tself.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=4)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)\n",
    "\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tinputs, labels = batch\n",
    "\t\toutputs = self(inputs)\n",
    "\t\tloss = self.criterion(outputs, labels)\n",
    "\n",
    "\t\t# Log loss and accuracy\n",
    "\t\tself.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\t\tself.train_accuracy(outputs, labels)\n",
    "\t\tself.log('train_acc', self.train_accuracy, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef validation_step(self, batch, batch_idx):\n",
    "\t\tinputs, labels = batch\n",
    "\t\toutputs = self(inputs)\n",
    "\t\tloss = self.criterion(outputs, labels)\n",
    "\n",
    "\t\t# Log loss and accuracy\n",
    "\t\tself.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "\t\tself.val_accuracy(outputs, labels)\n",
    "\t\tself.log('val_acc', self.val_accuracy, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "        # Define the optimizer\n",
    "\t\treturn torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\t\n",
    "\tdef on_test_start(self):\n",
    "\t\t# Register the hook to each multi-head attention layer before testing\n",
    "\t\tfor module in self.model.modules():\n",
    "\t\t\tif isinstance(module, torch.nn.MultiheadAttention):\n",
    "\t\t\t\tmodule.register_forward_hook(hook_fn)\n",
    "\n",
    "# Create the model instance\n",
    "model = BrainTumorClassifier()\n",
    "\n",
    "# Define the PyTorch Lightning Trainer\n",
    "trainer = L.Trainer(max_epochs=3, accelerator=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "trainer.test(model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
