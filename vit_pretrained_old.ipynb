{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import vit_b_16 # pretrained model\n",
    "from torchsummary import summary\n",
    "\n",
    "import brain_tumor_dataset as btd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\ttransforms.Grayscale(num_output_channels=3),\t# convert to 3 channels since pretrained model expects 3 channels\n",
    "\ttransforms.Resize((224, 224)), \t\t\t\t\t\n",
    "\ttransforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = btd.BrainTumorDataset(btd.TRAIN_DATA_PATH, transform=transform)\n",
    "test_dataset = btd.BrainTumorDataset(btd.TEST_DATA_PATH, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n",
      "{'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)\n",
    "print(test_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Conv2d: 1-1                                 [-1, 768, 14, 14]         590,592\n",
      "├─Encoder: 1-2                                [-1, 197, 768]            --\n",
      "|    └─Dropout: 2-1                           [-1, 197, 768]            --\n",
      "|    └─Sequential: 2-2                        [-1, 197, 768]            --\n",
      "|    |    └─EncoderBlock: 3-1                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-2                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-3                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-4                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-5                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-6                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-7                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-8                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-9                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-10                [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-11                [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-12                [-1, 197, 768]            7,087,872\n",
      "|    └─LayerNorm: 2-3                         [-1, 197, 768]            1,536\n",
      "├─Linear: 1-3                                 [-1, 4]                   3,076\n",
      "===============================================================================================\n",
      "Total params: 85,649,668\n",
      "Trainable params: 85,649,668\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 455.42\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 30.01\n",
      "Params size (MB): 326.73\n",
      "Estimated Total Size (MB): 357.31\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Conv2d: 1-1                                 [-1, 768, 14, 14]         590,592\n",
       "├─Encoder: 1-2                                [-1, 197, 768]            --\n",
       "|    └─Dropout: 2-1                           [-1, 197, 768]            --\n",
       "|    └─Sequential: 2-2                        [-1, 197, 768]            --\n",
       "|    |    └─EncoderBlock: 3-1                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-2                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-3                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-4                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-5                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-6                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-7                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-8                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-9                 [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-10                [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-11                [-1, 197, 768]            7,087,872\n",
       "|    |    └─EncoderBlock: 3-12                [-1, 197, 768]            7,087,872\n",
       "|    └─LayerNorm: 2-3                         [-1, 197, 768]            1,536\n",
       "├─Linear: 1-3                                 [-1, 4]                   3,076\n",
       "===============================================================================================\n",
       "Total params: 85,649,668\n",
       "Trainable params: 85,649,668\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 455.42\n",
       "===============================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 30.01\n",
       "Params size (MB): 326.73\n",
       "Estimated Total Size (MB): 357.31\n",
       "==============================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load pre-trained model\n",
    "model = vit_b_16(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Modify for 4 classes\n",
    "model.heads = torch.nn.Linear(model.hidden_dim, 4) \n",
    "\n",
    "model = model.to(device)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/3:   1%|          | 2/179 [00:51<1:15:30, 25.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n",
      "\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;32m---> 22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Accumulate loss for current batch\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Andreas\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n",
      "\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n",
      "\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n",
      "\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n",
      "\u001b[0;32m    520\u001b[0m     )\n",
      "\u001b[1;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n",
      "\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n",
      "\u001b[0;32m    523\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Andreas\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n",
      "\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n",
      "\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n",
      "\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n",
      "\u001b[1;32m--> 289\u001b[0m _engine_run_backward(\n",
      "\u001b[0;32m    290\u001b[0m     tensors,\n",
      "\u001b[0;32m    291\u001b[0m     grad_tensors_,\n",
      "\u001b[0;32m    292\u001b[0m     retain_graph,\n",
      "\u001b[0;32m    293\u001b[0m     create_graph,\n",
      "\u001b[0;32m    294\u001b[0m     inputs,\n",
      "\u001b[0;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[0;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[0;32m    297\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Andreas\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n",
      "\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n",
      "\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n",
      "\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n",
      "\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for current batch\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Calculate and print average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(module, input, output):\n",
    "    print(module)\n",
    "    print(f\"Input shape: {input[0].shape}\")\n",
    "    print(f\"Output shape: {output[0].shape}\")\n",
    "    print(\"===\")\n",
    "\n",
    "# Register the hook to the multihead attention module\n",
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.MultiheadAttention):\n",
    "        module.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model_pretrained.pth\", weights_only=True, map_location=device))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\n",
    "\tfor inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "\t\tinputs, labels = inputs.to(device), labels.to(device)\n",
    "\t\toutputs = model(inputs)\n",
    "\t\tpredictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "\t\ttotal += labels.size(0)\n",
    "\t\tcorrect += (predictions == labels).sum().item()\n",
    "\n",
    "\taccuracy = correct / total\n",
    "\tprint(f'Accuracy on the test set: {accuracy:.2%}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
